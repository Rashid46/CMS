{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On the Prediction of Software Defects for Embedded Real-time Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import math\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data from the Pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('x_train.pkl', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "\n",
    "with open('x_test.pkl', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "\n",
    "with open('y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open('y_test.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "    \n",
    "with open('x_traincm1.pkl', 'rb') as f:\n",
    "    x_traincm1 = pickle.load(f)\n",
    "\n",
    "with open('x_testcm1.pkl', 'rb') as f:\n",
    "    x_testcm1 = pickle.load(f)\n",
    "\n",
    "with open('y_traincm1.pkl', 'rb') as f:\n",
    "    y_traincm1 = pickle.load(f)\n",
    "\n",
    "with open('y_testcm1.pkl', 'rb') as f:\n",
    "    y_testcm1 = pickle.load(f)\n",
    "    \n",
    "with open('x_trainjm1.pkl', 'rb') as f:\n",
    "    x_trainjm1 = pickle.load(f)\n",
    "\n",
    "with open('x_testjm1.pkl', 'rb') as f:\n",
    "    x_testjm1 = pickle.load(f)\n",
    "\n",
    "with open('y_trainjm1.pkl', 'rb') as f:\n",
    "    y_trainjm1 = pickle.load(f)\n",
    "\n",
    "with open('y_testjm1.pkl', 'rb') as f:\n",
    "    y_testjm1 = pickle.load(f)\n",
    "    \n",
    "with open('x_trainkc1.pkl', 'rb') as f:\n",
    "    x_trainkc1 = pickle.load(f)\n",
    "\n",
    "with open('x_testkc1.pkl', 'rb') as f:\n",
    "    x_testkc1 = pickle.load(f)\n",
    "\n",
    "with open('y_trainkc1.pkl', 'rb') as f:\n",
    "    y_trainkc1 = pickle.load(f)\n",
    "\n",
    "with open('y_testkc1.pkl', 'rb') as f:\n",
    "    y_testkc1 = pickle.load(f)\n",
    "    \n",
    "with open('x_trainkc2.pkl', 'rb') as f:\n",
    "    x_trainkc2 = pickle.load(f)\n",
    "\n",
    "with open('x_testkc2.pkl', 'rb') as f:\n",
    "    x_testkc2 = pickle.load(f)\n",
    "\n",
    "with open('y_trainkc2.pkl', 'rb') as f:\n",
    "    y_trainkc2 = pickle.load(f)\n",
    "\n",
    "with open('y_testkc2.pkl', 'rb') as f:\n",
    "    y_testkc2 = pickle.load(f)\n",
    "    \n",
    "with open('x_trainpc1.pkl', 'rb') as f:\n",
    "    x_trainpc1 = pickle.load(f)\n",
    "\n",
    "with open('x_testpc1.pkl', 'rb') as f:\n",
    "    x_testpc1 = pickle.load(f)\n",
    "\n",
    "with open('y_trainpc1.pkl', 'rb') as f:\n",
    "    y_trainpc1 = pickle.load(f)\n",
    "\n",
    "with open('y_testpc1.pkl', 'rb') as f:\n",
    "    y_testpc1 = pickle.load(f)\n",
    "    \n",
    "with open('y_train_before1.pkl', 'rb') as f:\n",
    "    y_train_before = pickle.load(f)\n",
    "\n",
    "with open('y_test_before1.pkl', 'rb') as f:\n",
    "    y_test_before = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "with open('y_train_before1cm1.pkl', 'rb') as f:\n",
    "    y_train_beforecm1 = pickle.load(f)\n",
    "\n",
    "with open('y_test_before1cm1.pkl', 'rb') as f:\n",
    "    y_test_beforecm1 = pickle.load(f)\n",
    "    \n",
    "with open('y_train_before1jm1.pkl', 'rb') as f:\n",
    "    y_train_beforejm1 = pickle.load(f)\n",
    "\n",
    "with open('y_test_before1jm1.pkl', 'rb') as f:\n",
    "    y_test_beforejm1 = pickle.load(f)\n",
    "    \n",
    "with open('y_train_before1kc1.pkl', 'rb') as f:\n",
    "    y_train_beforekc1 = pickle.load(f)\n",
    "\n",
    "with open('y_test_before1kc1.pkl', 'rb') as f:\n",
    "    y_test_beforekc1 = pickle.load(f)\n",
    "    \n",
    "with open('y_train_before1kc2.pkl', 'rb') as f:\n",
    "    y_train_beforekc2 = pickle.load(f)\n",
    "\n",
    "with open('y_test_before1kc2.pkl', 'rb') as f:\n",
    "    y_test_beforekc2 = pickle.load(f)\n",
    "    \n",
    "with open('y_train_before1pc1.pkl', 'rb') as f:\n",
    "    y_train_beforepc1 = pickle.load(f)\n",
    "\n",
    "with open('y_test_before1pc1.pkl', 'rb') as f:\n",
    "    y_test_beforepc1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Creating a two layer perceptron based neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network_architecture(x, hid1_size, hid2_size):\n",
    "    '''\n",
    "    Creates a 2-layer perceptron based on hidden sizes\n",
    "    '''\n",
    "    # Input layer -> Hidden layer\n",
    "    W1 = tf.Variable(tf.random_normal([21, hid1_size]), trainable=True, name = 'W1')\n",
    "    # Hidden layer -> Output layer\n",
    "    W2 = tf.Variable(tf.random_normal([hid1_size, hid2_size]), trainable=True, name = 'W2')\n",
    "\n",
    "    # Hidden layer\n",
    "    hid_out1 = tf.matmul(x, W1)\n",
    "    hid_out2 = tf.nn.bias_add(hid_out1, tf.constant(1, dtype=tf.float32, shape=[hid1_size]), name='Bias1')\n",
    "    hid_out = tf.nn.sigmoid(hid_out2)\n",
    "\n",
    "    # Output Layer\n",
    "    out1 = tf.matmul(hid_out, W2)\n",
    "    out2 = tf.nn.bias_add(out1, tf.constant(1, dtype=tf.float32, shape=[hid2_size]), name='Bias2')\n",
    "    out  = out2 \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "l_rate        = 1e-4\n",
    "epochs        = 500\n",
    "batch_size    = 300\n",
    "hidden1_size  = 20\n",
    "hidden2_size  = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training two layer perceptron based neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_layer_perceptron(x_train, y_train, x_test, y_test):\n",
    "    # Input Placeholders \n",
    "    x = tf.placeholder(tf.float32, [None, 21])\n",
    "    y = tf.placeholder(tf.float32, [None, 2]) \n",
    "    # Create network\n",
    "    y_ = network_architecture(x, hidden1_size, hidden2_size)\n",
    "    # Loss function\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_)) \n",
    "    # Optimization algorithm\n",
    "    \n",
    "    optim = tf.train.AdamOptimizer(learning_rate=l_rate).minimize(cross_entropy)\n",
    "    # Initializer\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    # Accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    print('Training_Set: ', len(x_train))\n",
    "    print('Testing_Set : ', len(x_test))\n",
    "\n",
    "    cost = []\n",
    "\n",
    "    with tf.Session() as sess: \n",
    "        sess.run(init_op)\n",
    "        for epoch in range(epochs):\n",
    "            #x_train, y_train = shuffle_in_unison(x_train, y_train)\n",
    "            for batch in range(0, len(x_train), batch_size):\n",
    "                batch_x = x_train[batch:(batch+batch_size)]\n",
    "                batch_y = y_train[batch:(batch+batch_size)]\n",
    "                \n",
    "            _, loss = sess.run([optim, cross_entropy], feed_dict = {x : batch_x, y : batch_y})\n",
    "        \n",
    "        cost.append(loss)\n",
    "        print(\"\\nTraining Done!\")\n",
    "        print('The accuracy for our test batch is   ', sess.run(accuracy, feed_dict={x: x_test, y: y_test}))\n",
    "    sess.close()\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Set:  12098\n",
      "Testing_Set :  3025\n",
      "\n",
      "Training Done!\n",
      "The accuracy for our test batch is    0.827438\n",
      "Training_Set:  398\n",
      "Testing_Set :  100\n",
      "\n",
      "Training Done!\n",
      "The accuracy for our test batch is    0.92\n",
      "Training_Set:  8708\n",
      "Testing_Set :  2177\n",
      "\n",
      "Training Done!\n",
      "The accuracy for our test batch is    0.80248\n",
      "Training_Set:  1687\n",
      "Testing_Set :  422\n",
      "\n",
      "Training Done!\n",
      "The accuracy for our test batch is    0.194313\n",
      "Training_Set:  417\n",
      "Testing_Set :  105\n",
      "\n",
      "Training Done!\n",
      "The accuracy for our test batch is    0.790476\n",
      "Training_Set:  887\n",
      "Testing_Set :  222\n",
      "\n",
      "Training Done!\n",
      "The accuracy for our test batch is    0.68018\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4b755d473994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcostpc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwo_layer_perceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_trainpc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trainpc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_testpc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_testpc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "cost = two_layer_perceptron(x_train, y_train, x_test, y_test)\n",
    "costcm1 = two_layer_perceptron(x_traincm1, y_traincm1, x_testcm1, y_testcm1)\n",
    "costjm1 = two_layer_perceptron(x_trainjm1, y_trainjm1, x_testjm1, y_testjm1)\n",
    "costkc1 = two_layer_perceptron(x_trainkc1, y_trainkc1, x_testkc1, y_testkc1)\n",
    "costkc2 = two_layer_perceptron(x_trainkc2, y_trainkc2, x_testkc2, y_testkc2)\n",
    "costpc1 = two_layer_perceptron(x_trainpc1, y_trainpc1, x_testpc1, y_testpc1)\n",
    "\n",
    "print(cost.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = np.floor(np.linspace(0, epochs, epochs))\n",
    "plt.plot(ax, cost, color='b')\n",
    "plt.title('Training loss', fontsize=15)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "pp = PdfPages('TrainingLossOverall.pdf')\n",
    "pp.savefig(plt)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (500,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d9362586f2f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraininglossPlot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-8a4ffd50b3eb>\u001b[0m in \u001b[0;36mtraininglossPlot\u001b[1;34m(cost)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\100631155\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3315\u001b[0m                       mplDeprecation)\n\u001b[0;32m   3316\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3317\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3318\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3319\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\100631155\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1895\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1896\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1898\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\100631155\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\100631155\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\100631155\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\100631155\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 244\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (500,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x76756a12b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traininglossPlot(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Set:  8708\n",
      "Testing_Set :  2177\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'init_op' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-868d842514ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#x_train, y_train = shuffle_in_unison(x_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'init_op' is not defined"
     ]
    }
   ],
   "source": [
    "print('Training_Set: ', len(x_trainjm1))\n",
    "print('Testing_Set : ', len(x_testjm1))\n",
    "\n",
    "cost = []\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init_op)\n",
    "    for epoch in range(epochs):\n",
    "        #x_train, y_train = shuffle_in_unison(x_train, y_train)\n",
    "        for batch in range(0, len(x_trainjm1), batch_size):\n",
    "            batch_x = x_trainjm1[batch:(batch+batch_size)]\n",
    "            batch_y = y_trainjm1[batch:(batch+batch_size)]\n",
    "            \n",
    "            _, loss = sess.run([optim, cross_entropy], feed_dict = {x : batch_x, y : batch_y})\n",
    "        \n",
    "        cost.append(loss)\n",
    "    \n",
    "    print(\"\\nTraining Done!\")\n",
    "    print('The accuracy for our test batch is   ', sess.run(accuracy, feed_dict={x: x_testjm1, y: y_testjm1}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ax = np.floor(np.linspace(0, epochs, epochs))\n",
    "plt.plot(ax, cost, color='b')\n",
    "plt.title('Training loss for JM1', fontsize=15)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training_Set: ', len(x_trainkc1))\n",
    "print('Testing_Set : ', len(x_testkc1))\n",
    "\n",
    "cost = []\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init_op)\n",
    "    for epoch in range(epochs):\n",
    "        #x_train, y_train = shuffle_in_unison(x_train, y_train)\n",
    "        for batch in range(0, len(x_trainkc1), batch_size):\n",
    "            batch_x = x_trainkc1[batch:(batch+batch_size)]\n",
    "            batch_y = y_trainkc1[batch:(batch+batch_size)]\n",
    "            \n",
    "            _, loss = sess.run([optim, cross_entropy], feed_dict = {x : batch_x, y : batch_y})\n",
    "        \n",
    "        cost.append(loss)\n",
    "    \n",
    "    print(\"\\nTraining Done!\")\n",
    "    print('The accuracy for our test batch is   ', sess.run(accuracy, feed_dict={x: x_testkc1, y: y_testkc1}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ax = np.floor(np.linspace(0, epochs, epochs))\n",
    "plt.plot(ax, cost, color='b')\n",
    "plt.title('Training loss KC1', fontsize=15)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training_Set: ', len(x_trainkc2))\n",
    "print('Testing_Set : ', len(x_testkc2))\n",
    "\n",
    "cost = []\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init_op)\n",
    "    for epoch in range(epochs):\n",
    "        #x_train, y_train = shuffle_in_unison(x_train, y_train)\n",
    "        for batch in range(0, len(x_train), batch_size):\n",
    "            batch_x = x_trainkc2[batch:(batch+batch_size)]\n",
    "            batch_y = y_trainkc2[batch:(batch+batch_size)]\n",
    "            \n",
    "            _, loss = sess.run([optim, cross_entropy], feed_dict = {x : batch_x, y : batch_y})\n",
    "        \n",
    "        cost.append(loss)\n",
    "    \n",
    "    print(\"\\nTraining Done!\")\n",
    "    print('The accuracy for our test batch is   ', sess.run(accuracy, feed_dict={x: x_testkc2, y: y_testkc2}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ax = np.floor(np.linspace(0, epochs, epochs))\n",
    "plt.plot(ax, cost, color='b')\n",
    "plt.title('Training loss', fontsize=15)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training_Set: ', len(x_trainpc1))\n",
    "print('Testing_Set : ', len(x_testpc1))\n",
    "\n",
    "cost = []\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init_op)\n",
    "    for epoch in range(epochs):\n",
    "        #x_train, y_train = shuffle_in_unison(x_train, y_train)\n",
    "        for batch in range(0, len(x_trainpc1), batch_size):\n",
    "            batch_x = x_trainpc1[batch:(batch+batch_size)]\n",
    "            batch_y = y_trainpc1[batch:(batch+batch_size)]\n",
    "            \n",
    "            _, loss = sess.run([optim, cross_entropy], feed_dict = {x : batch_x, y : batch_y})\n",
    "        \n",
    "        cost.append(loss)\n",
    "    \n",
    "    print(\"\\nTraining Done!\")\n",
    "    print('The accuracy for our test batch is   ', sess.run(accuracy, feed_dict={x: x_testpc1, y: y_testpc1}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ax = np.floor(np.linspace(0, epochs, epochs))\n",
    "plt.plot(ax, cost, color='b')\n",
    "plt.title('Training loss KC1', fontsize=15)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training_Set: ', len(x_traincm1))\n",
    "print('Testing_Set : ', len(x_testcm1))\n",
    "\n",
    "cost = []\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init_op)\n",
    "    for epoch in range(epochs):\n",
    "        #x_train, y_train = shuffle_in_unison(x_train, y_train)\n",
    "        for batch in range(0, len(x_traincm1), batch_size):\n",
    "            batch_x = x_traincm1[batch:(batch+batch_size)]\n",
    "            batch_y = y_traincm1[batch:(batch+batch_size)]\n",
    "            \n",
    "            _, loss = sess.run([optim, cross_entropy], feed_dict = {x : batch_x, y : batch_y})\n",
    "        \n",
    "        cost.append(loss)\n",
    "    \n",
    "    print(\"\\nTraining Done!\")\n",
    "    print('The accuracy for our test batch is   ', sess.run(accuracy, feed_dict={x: x_testcm1, y: y_testcm1}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ax = np.floor(np.linspace(0, epochs, epochs))\n",
    "plt.plot(ax, cost, color='b')\n",
    "plt.title('Training loss for CM1', fontsize=15)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Hidden layer size and checking Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_layer_perceptron(x_train, y_train, x_test, y_test):\n",
    "    # Delete any previous sessions\n",
    "    layer_size_cost = {}\n",
    "    for i in range(3, 21):\n",
    "        print('Current Hidden Layer Size:', i)\n",
    "        # Hidden layer sizes\n",
    "        hidden1_size  = i\n",
    "        hidden2_size  = 2\n",
    "        \n",
    "        # Input Placeholders \n",
    "        x = tf.placeholder(tf.float32, [None, 21])\n",
    "        y = tf.placeholder(tf.float32, [None, 2]) \n",
    "        \n",
    "        # Create network\n",
    "        y_ = network_architecture(x, hidden1_size, hidden2_size)\n",
    "        \n",
    "        # Loss function\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_)) \n",
    "        \n",
    "        # Optimization algorithm\n",
    "        optim = tf.train.AdamOptimizer(learning_rate=l_rate).minimize(cross_entropy)\n",
    "    \n",
    "        # Initializer\n",
    "        init_op = tf.global_variables_initializer()\n",
    "    \n",
    "        # Accuracy\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        # Training Loss\n",
    "        cost = []\n",
    "\n",
    "        with tf.Session() as sess: \n",
    "            sess.run(init_op)\n",
    "            for epoch in range(epochs):\n",
    "                #x_train, y_train = shuffle_in_unison(x_train, y_train)\n",
    "                for batch in range(0, len(x_train), batch_size):\n",
    "                    batch_x = x_train[batch:(batch+batch_size)]\n",
    "                    batch_y = y_train[batch:(batch+batch_size)]\n",
    "\n",
    "                _, loss = sess.run([optim, cross_entropy], feed_dict = {x : batch_x, y : batch_y})\n",
    "\n",
    "                cost.append(loss)\n",
    "\n",
    "            print(\"\\nTraining Done!\")\n",
    "            current_hidden_size_acc = sess.run(accuracy, feed_dict={x: x_test, y: y_test})\n",
    "            print('The accuracy for our test batch is: ', current_hidden_size_acc)\n",
    "\n",
    "        sess.close()\n",
    "    \n",
    "        # Save the loss and accuracy into a dict \n",
    "        layer_size_cost[str(i)] = cost\n",
    "        layer_size_cost[(str(i) + '_acc')] = current_hidden_size_acc\n",
    "\n",
    "        # Delete previous session\n",
    "        del sess\n",
    "    \n",
    "    \n",
    "        return layer_size_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Hidden Layer Size: 3\n",
      "\n",
      "Training Done!\n",
      "The accuracy for our test batch is:  0.230413\n"
     ]
    }
   ],
   "source": [
    "layer_size_cost = multi_layer_perceptron(x_train, y_train, x_test, y_test)\n",
    "# layer_size_costcm1 = multi_layer_perceptron(x_traincm1, y_traincm1, x_testcm1, y_testcm1)\n",
    "# layer_size_costjm1 = multi_layer_perceptron(x_trainjm1, y_trainjm1, x_testjm1, y_testjm1)\n",
    "# layer_size_costkc1 = multi_layer_perceptron(x_trainkc1, y_trainkc1, x_testkc1, y_testkc1)\n",
    "# layer_size_costkc2 = multi_layer_perceptron(x_trainkc2, y_trainkc2, x_testkc2, y_testkc2)\n",
    "# layer_size_costpc1 = multi_layer_perceptron(x_trainpc1, y_trainpc1, x_testpc1, y_testpc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Accuracy-vs-Hidden Layer Increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_hidden()\n",
    "layer_size_vs_acc = []\n",
    "\n",
    "for i in range(3, 21, 1):\n",
    "    get_acc = str(i) + '_acc'\n",
    "    layer_size_vs_acc.append(layer_size_cost[get_acc])\n",
    "    ax = np.floor(np.linspace(3, 20, 18))\n",
    "    \n",
    "plt.plot(ax, layer_size_vs_acc )\n",
    "plt.title('Test Accuracy vs Hidden Layer Size', fontsize=15)\n",
    "plt.xlabel('Hidden Layer Size')\n",
    "plt.ylabel('Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_accuracy_hidden(layer_size_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_error_vs_epoch():\n",
    "    ax = np.floor(np.linspace(3, 20, 500))\n",
    "    for i in range(3, 20, 4):\n",
    "        plt.plot(ax, layer_size_cost[str(i)], label='$Hidden size = {i}$'.format(i=i))\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Training error vs Epoch', fontsize=15)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
